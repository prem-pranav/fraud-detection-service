# ğŸ›¡ï¸ Advanced Fraud Detection System

> A production-ready, financially optimized machine learning pipeline for real-time transaction risk assessment.

This repository implements an end-to-end fraud detection solution that bridges the gap between exploratory research and high-stakes production environments. The system is engineered for **stability**, **calibration**, and **profit maximization**.

---

## ğŸ› ï¸ Core Technology Stack

| Component     | Technology                        |
| :------------ | :-------------------------------- |
| **Language**  | Python 3.x                        |
| **ML Engine** | LightGBM, XGBoost                 |
| **Data Ops**  | Pandas, NumPy                     |
| **Inference** | Joblib, Isotonic Calibration      |
| **Analysis**  | Scikit-Learn, Matplotlib, Seaborn |

---

## ğŸš¦ Key Project Highlights

- **ğŸ¯ Precision Calibration**: Uses Isotonic Regression to map model scores to true empirical fraud probabilities ($P(Fraud|Score)$).
- **ğŸ’¸ Financial Optimization**: Integrated an optimal decision threshold (**0.267**) mathematically tuned to minimize total business loss (Fraud Cost + Review Friction).
- **ğŸ›¡ï¸ Production Stability**: Achieved a highly stable **91.90% AUC-ROC** and **60.04% PR-AUC** with cross-validation variance $<0.3\%$.
- **âš¡ Decoupled Inference**: Standalone `--predict` mode supports large-scale batch scoring without retraining.

---

## ğŸ“ˆ Engineering Roadmap

### 1ï¸âƒ£ Exploratory Foundation

Understand data distributions and established a baseline preprocessing strategy to handle high-cardinality categorical variables.

- ğŸ“– **Walkthrough**: [Exploratory Data Analysis](eda.md)
- ğŸ’» **Script**: `eda.py`

### 2ï¸âƒ£ Stability & Performance Research

A rigorous two-phase study was conducted to select the optimal model architecture and class-balancing weights.

- ğŸ“– **Walkthrough**: [Model Performance Analysis](model_performance_analysis.md)
- ğŸ’» **Script**: `model_performance_analysis.py`

### 3ï¸âƒ£ Production-Grade Development

Implementation of the "Gold Model" with robust column harmonization, stateful encoding, and probability calibration.

- ğŸ“– **Walkthrough**: [Production Development Walkthrough](model_development.md)
- ğŸ’» **Script**: `model_development.py`

### 4ï¸âƒ£ Actionable Decision Layer

The system translates ML scores into clear business recommendations: `AUTO_PASS`, `MANUAL_REVIEW`, or `AUTO_BLOCK`.

---

## âš™ï¸ Environment Setup

Before running any scripts, ensure you have initialized the virtual environment and installed the dependencies.

```powershell
# 1. Create the virtual environment
python -m venv .venv

# 2. Activate the environment
.\.venv\Scripts\activate

# 3. Install required libraries
pip install -r python-libraries.txt
```

---

## ğŸš€ Execution Guide

This project contains several scripts for different phases of the ML lifecycle. All commands should be run within the activated virtual environment.

### 1ï¸âƒ£ Initial Data Discovery (EDA)
Run the exploratory analysis to generate data distribution plots and initial insights.
```powershell
.\.venv\Scripts\python eda.py
```
*Outputs: Visualizations in `images/eda-img/`*

### 2ï¸âƒ£ Model Stability Research
Execute the comprehensive stability analysis to compare LightGBM vs. XGBoost and find optimal weights.
```powershell
.\.venv\Scripts\python model_performance_analysis.py
```
*Outputs: Stability plots and cost curves in `images/model-perf-analysis-img/`*

### 3ï¸âƒ£ Production Training
Train the final "Gold Model" with full data, fit the probability calibrator, and save production artifacts.
```powershell
.\.venv\Scripts\python model_development.py --train
```
*Artifacts: `models/*.pkl`*

### 4ï¸âƒ£ Standalone Inference
Score target data using the calibrated production model.

**Full Test Set:**
```powershell
.\.venv\Scripts\python model_development.py --predict
```

**Custom Input Batch:**
```powershell
.\.venv\Scripts\python model_development.py --predict --txn my_data_txn.csv --id my_data_id.csv --out final_results.csv --limit 1000
```

---

## ğŸ“‚ Project Structure

```text
â”œâ”€â”€ .venv/                       # Python Virtual Environment
â”œâ”€â”€ .gitattributes                # Git handling for large binary CSVs
â”œâ”€â”€ .gitignore                   # Excludes large data, models, and cache
â”œâ”€â”€ model_development.py         # Primary Production Entry Point (Train/Predict)
â”œâ”€â”€ model_development.md         # Production Implementation Details
â”œâ”€â”€ model_performance_analysis.py # Stability Research & Benchmarking Script
â”œâ”€â”€ model_performance_analysis.md # Detailed Performance Findings
â”œâ”€â”€ eda.py                       # Preliminary Exploratory Analysis Script
â”œâ”€â”€ eda.md                       # Initial Data Insights Documentation
â”œâ”€â”€ models/                      # Serialized Artifacts (.pkl)
â”‚   â”œâ”€â”€ fraud_model_lgb_v1.pkl   # Trained LightGBM model
â”‚   â”œâ”€â”€ calibrator_v1.pkl        # Isotonic probability calibrator
â”‚   â””â”€â”€ ...                      # Other production artifacts
â”œâ”€â”€ ecom-payment-txn/            # ğŸ“¦ RAW DATASET (Ignored by Git)
â”‚   â”œâ”€â”€ train_transaction.csv    # Main transaction features & labels
â”‚   â”œâ”€â”€ train_identity.csv       # Device/Network info for training
â”‚   â”œâ”€â”€ test_transaction.csv     # Unlabelled test transactions
â”‚   â””â”€â”€ test_identity.csv        # Device/Network info for testing
â”œâ”€â”€ images/                      # ğŸ“Š VISUAL ANALYTICS
â”‚   â”œâ”€â”€ eda-img/                 # Exploratory plots (distributions, correlations)
â”‚   â””â”€â”€ model-perf-analysis-img/ # Stability, ROC/PR curves, & business cost curves
â””â”€â”€ test_result.csv              # Default output for inference predictions
```
